{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN32EKraw5LXcsP1nzXdEii"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"-bl6HsY9vVjR"},"outputs":[],"source":["# Library to suppress warnings or deprecation notes \n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","import os\n","import math\n","\n","# Libraries to help with reading and manipulating data\n","import numpy as np\n","import pandas as pd\n","import glob\n","from tqdm import tqdm"]},{"cell_type":"code","source":["def clean_weather_column_names(df):\n","    '''Strip out blanks in weather dataframe columns\n","        :df: DataFrame to use\n","    '''\n","    df.rename(columns=lambda x: x.strip(), inplace = True)\n","    return df\n","\n","def create_single_weather_file(directory, prefix, suffix = '*.txt', lines_to_skip=19):\n","    '''Read all the weather files in a directory and create a concatenated dataframe\n","        :directory: Directory with weather file\n","        :prefix: The prefix of the weather file to look for in the directory\n","        :suffix: The suffix of the weather file to look for in the directory default is *.txt\n","        :lines_to_skip: Number of lines to skip in the files before csv header default is 19\n","    '''\n","    directory_mask = os.path.join(directory, prefix + suffix)\n","    \n","    # Find list of matching filenames in the directory\n","    filenames = glob.glob(directory_mask)\n","    concat_df = None\n","    \n","    if (len(filenames) > 0):\n","        df_list = []\n","        for filename in filenames:\n","            df_list.append(pd.read_csv(filename, skiprows=lines_to_skip))\n","\n","        concat_df = pd.concat(df_list, axis=0)\n","        concat_df = clean_weather_column_names(concat_df)\n","    else:\n","        print('No files found in {} for prefix {}'.format(directory, prefix))\n","        \n","    return concat_df\n","\n","def process_weather_files(root_directory, output_directory, min_date='2016-12-31'):\n","    '''Process all the weather file directories\n","        :root_directory: Root directory containing the weather file subdirectories\n","        :output_directory: Directory to output merged files\n","        :min_date: The min date to exclude from the date range after building the combined file default is 12/31/2016\n","    '''\n","    \n","    # Mapping between leaf names and file name prefix in child directory\n","    directory_dict = {'ECA_cloud_cover': 'CC','ECA_global_radiation': 'QQ','ECA_humidity': 'HU',\n","                'ECA_mean_temperature': 'TG','ECA_precipitation': 'RR','ECA_sea_level_pressure': 'PP',\n","                'ECA_snow depth': 'SD','ECA_sunshine': 'SS','ECA_wind_speed': 'FG'}\n","    \n","    for key, value in tqdm(directory_dict.items()):\n","        # Concatenate files into a single dateframe\n","        current_directory = os.path.join(root_directory, key)\n","        prefix = value\n","        #print('Processing {}'.format(current_directory))\n","        combined_df = create_single_weather_file(current_directory, prefix)\n","\n","        # Convert DATE column to datetime so we can filter 2017-2021\n","        combined_df['DATE'] = pd.to_datetime(combined_df['DATE'].astype(str))\n","        combined_df = combined_df[combined_df['DATE'] > min_date]\n","\n","        # output a single file\n","        output_file = os.path.join(output_directory, 'Combined_{}_{}.csv'.format(prefix, key))\n","        #print('\\tWriting {}'.format(output_file))\n","        combined_df.to_csv(output_file, index=False)\n","        #print(combined_df.head())\n","\n","        #Create dataframe for the sources.txt file\n","        #Number of lines to skip in the sources.txt files before csv header is 23\n","        sources_df = pd.read_csv(os.path.join(current_directory, 'sources.txt'), skiprows=23)\n","        sources_df.rename(columns=lambda x: x.strip(), inplace = True) #strip extra white space from column names\n","        sources_df['BEGIN'] = pd.to_datetime(sources_df['BEGIN'].astype(str)) #format the date columns\n","        sources_df['END'] = pd.to_datetime(sources_df['END'].astype(str)) #format the date columns\n","        sources_df['SOUNAME'] = sources_df['SOUNAME'].str.strip() #strip leading / trailing white spaces from the column\n","        sources_df['PARNAME'] = sources_df['PARNAME'].str.strip() #strip leading / trailing white spaces from the column\n","        sources_df['PARID'] = sources_df['PARID'].str.strip() #strip leading / trailing white spaces from the column\n","        #print(sources_df.head())\n","        sources_output_file = os.path.join(output_directory, 'sources_{}_{}.csv'.format(prefix, key))\n","        sources_df.to_csv(sources_output_file, index=False)\n","\n","        #break"],"metadata":{"id":"L0KUYAJYvee7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Root directory of the weather files from zip\n","root_directory = '/home/rukshar/Documents/Omdena/Poland/Air Quality/Data/daily_weather_data/daily_weather_data_1979-2021'\n","\n","# Output directory for combined file\n","output_directory = '/home/rukshar/Documents/Omdena/Poland/Air Quality/Data/processed_weather_data'\n","process_weather_files(root_directory, output_directory)"],"metadata":{"id":"Q7zUwtdnvhDS"},"execution_count":null,"outputs":[]}]}